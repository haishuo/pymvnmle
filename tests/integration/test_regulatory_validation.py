#!/usr/bin/env python3
"""
Regulatory Validation Test Suite for PyMVNMLE
==============================================

This test suite provides comprehensive validation against R's mvnmle package
for regulatory submission purposes. All tests must pass for FDA compliance.

Run with: python -m pytest tests/test_regulatory_validation.py -v
Or: python tests/test_regulatory_validation.py

Author: PyMVNMLE Development Team
Purpose: FDA-grade validation against R reference implementation
Standard: Regulatory submission grade
"""

import numpy as np
import pytest
import json
import warnings
from pathlib import Path
import sys
import os

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

# Import PyMVNMLE
try:
    from pymvnmle import mlest, datasets
    from pymvnmle._validation import run_validation_suite
except ImportError as e:
    print(f"Failed to import PyMVNMLE: {e}")
    print("Please ensure PyMVNMLE is installed or run from project root")
    sys.exit(1)


class TestRegulatoryValidation:
    """
    Regulatory validation tests against R mvnmle package.
    
    These tests form the core validation suite for FDA submission.
    All tests must pass for regulatory compliance.
    """
    
    def setup_method(self):
        """Setup for each test method."""
        # Suppress optimization warnings for cleaner test output
        warnings.filterwarnings('ignore', category=UserWarning, module='scipy')
        
    def test_apple_dataset_exact_validation(self):
        """
        Test Apple dataset against exact R reference results.
        
        REGULATORY REQUIREMENT: Must match R mvnmle results within specified tolerance.
        This test validates the core algorithm against a well-established benchmark.
        """
        print("\nüçé REGULATORY TEST: Apple Dataset Validation")
        print("=" * 60)
        
        # Run estimation
        result = mlest(datasets.apple, verbose=False)
        
        # R reference results (from generate_r_references.R)
        r_reference = {
            'muhat': [14.722265587140136, 49.333248446740669],
            'sigmahat': [
                [89.534149681512773, -90.696532296720122],
                [-90.696532296720122, 114.69470032845283]
            ],
            'loglik': -74.217476133121025
        }
        
        # Validation tolerances (regulatory standard)
        param_tolerance = 1e-3  # 0.1% for parameters
        loglik_tolerance = 1e-7  # Machine precision for log-likelihood
        
        # Test convergence
        assert result.converged, f"Apple dataset failed to converge: {result.convergence_message}"
        
        # Test mean estimates
        mu_diff = np.max(np.abs(result.muhat - r_reference['muhat']))
        assert mu_diff < param_tolerance, (
            f"Mean estimates differ by {mu_diff:.2e} > tolerance {param_tolerance:.0e}\n"
            f"Python: {result.muhat}\n"
            f"R ref:  {r_reference['muhat']}"
        )
        
        # Test covariance estimates
        sigma_diff = np.max(np.abs(result.sigmahat - r_reference['sigmahat']))
        assert sigma_diff < param_tolerance, (
            f"Covariance estimates differ by {sigma_diff:.2e} > tolerance {param_tolerance:.0e}\n"
            f"Max difference in covariance matrix exceeds regulatory tolerance"
        )
        
        # Test log-likelihood (most critical)
        loglik_diff = abs(result.loglik - r_reference['loglik'])
        assert loglik_diff < loglik_tolerance, (
            f"Log-likelihood differs by {loglik_diff:.2e} > tolerance {loglik_tolerance:.0e}\n"
            f"Python: {result.loglik:.10f}\n"
            f"R ref:  {r_reference['loglik']:.10f}"
        )
        
        print(f"‚úÖ Mean difference: {mu_diff:.2e} (tolerance: {param_tolerance:.0e})")
        print(f"‚úÖ Covariance difference: {sigma_diff:.2e} (tolerance: {param_tolerance:.0e})")
        print(f"‚úÖ Log-likelihood difference: {loglik_diff:.2e} (tolerance: {loglik_tolerance:.0e})")
        print("‚úÖ REGULATORY VALIDATION: APPLE DATASET PASSED")
    
    def test_missvals_dataset_exact_validation(self):
        """
        Test Missvals dataset against exact R reference results.
        
        REGULATORY REQUIREMENT: Must handle complex missing data patterns.
        This dataset has 5 variables with intricate missingness patterns.
        """
        print("\nüìä REGULATORY TEST: Missvals Dataset Validation")
        print("=" * 60)
        
        # Run estimation with higher iteration limit (matching R)
        result = mlest(datasets.missvals, max_iter=400, verbose=False)
        
        # R reference results (from generate_r_references.R)
        r_reference = {
            'muhat': [6.6551660306808111, 49.965258011630283, 11.769230501209805, 
                     27.047090472686431, 95.423076760497381],
            'sigmahat': [
                [21.825568787239664, 20.864341285827901, -24.900388855506396, -11.473448545211733, 46.953038117192904],
                [20.864341285827901, 238.01241053145014, -15.817377384383333, -252.07228960405672, 195.60362068104104],
                [-24.900388855506396, -15.817377384383333, 37.869824468131164, -9.5992127298212324, -47.556216057213561],
                [-11.473448545211733, -252.07228960405672, -9.5992127298212324, 294.18303268448375, -190.59848378080528],
                [46.953038117192904, 195.60362068104104, -47.556216057213561, -190.59848378080528, 208.90487129864388]
            ],
            'loglik': -86.978323784901889
        }
        
        # More lenient tolerances for complex dataset
        param_tolerance = 5e-3  # 0.5% for complex missing data patterns  
        loglik_tolerance = 1e-6  # Still strict for log-likelihood
        
        # Test convergence
        assert result.converged, f"Missvals dataset failed to converge: {result.convergence_message}"
        
        # Test mean estimates
        mu_diff = np.max(np.abs(result.muhat - r_reference['muhat']))
        assert mu_diff < param_tolerance, (
            f"Mean estimates differ by {mu_diff:.2e} > tolerance {param_tolerance:.0e}\n"
            f"Complex missing data patterns require higher tolerance"
        )
        
        # Test covariance estimates
        sigma_diff = np.max(np.abs(result.sigmahat - r_reference['sigmahat']))
        assert sigma_diff < param_tolerance, (
            f"Covariance estimates differ by {sigma_diff:.2e} > tolerance {param_tolerance:.0e}\n"
            f"Complex missing data patterns require higher tolerance"
        )
        
        # Test log-likelihood (critical for mathematical equivalence)
        loglik_diff = abs(result.loglik - r_reference['loglik'])
        assert loglik_diff < loglik_tolerance, (
            f"Log-likelihood differs by {loglik_diff:.2e} > tolerance {loglik_tolerance:.0e}\n"
            f"Mathematical equivalence violated"
        )
        
        print(f"‚úÖ Mean difference: {mu_diff:.2e} (tolerance: {param_tolerance:.0e})")
        print(f"‚úÖ Covariance difference: {sigma_diff:.2e} (tolerance: {param_tolerance:.0e})")
        print(f"‚úÖ Log-likelihood difference: {loglik_diff:.2e} (tolerance: {loglik_tolerance:.0e})")
        print("‚úÖ REGULATORY VALIDATION: MISSVALS DATASET PASSED")
    
    def test_mathematical_properties(self):
        """
        Test fundamental mathematical properties of ML estimates.
        
        REGULATORY REQUIREMENT: Estimates must satisfy mathematical constraints.
        """
        print("\nüî¨ REGULATORY TEST: Mathematical Properties")
        print("=" * 60)
        
        datasets_to_test = [
            ("Apple", datasets.apple),
            ("Missvals", datasets.missvals)
        ]
        
        for name, data in datasets_to_test:
            result = mlest(data, verbose=False)
            
            # Test 1: Covariance matrix positive definiteness
            eigenvals = np.linalg.eigvalsh(result.sigmahat)
            min_eigenval = np.min(eigenvals)
            assert min_eigenval > 0, (
                f"{name}: Covariance matrix not positive definite\n"
                f"Minimum eigenvalue: {min_eigenval:.2e}"
            )
            
            # Test 2: Covariance matrix symmetry
            symmetry_error = np.max(np.abs(result.sigmahat - result.sigmahat.T))
            assert symmetry_error < 1e-14, (
                f"{name}: Covariance matrix not symmetric\n"
                f"Symmetry error: {symmetry_error:.2e}"
            )
            
            # Test 3: Finite estimates
            assert np.all(np.isfinite(result.muhat)), f"{name}: Non-finite mean estimates"
            assert np.all(np.isfinite(result.sigmahat)), f"{name}: Non-finite covariance estimates"
            assert np.isfinite(result.loglik), f"{name}: Non-finite log-likelihood"
            
            print(f"‚úÖ {name}: Positive definite (min eigenvalue: {min_eigenval:.2e})")
            print(f"‚úÖ {name}: Symmetric (error: {symmetry_error:.2e})")
            print(f"‚úÖ {name}: All estimates finite")
        
        print("‚úÖ REGULATORY VALIDATION: MATHEMATICAL PROPERTIES PASSED")
    
    def test_edge_cases_and_robustness(self):
        """
        Test algorithm robustness with challenging datasets.
        
        REGULATORY REQUIREMENT: Must handle edge cases gracefully.
        """
        print("\nüõ°Ô∏è REGULATORY TEST: Edge Cases and Robustness")
        print("=" * 60)
        
        # Test 1: Near-singular covariance
        np.random.seed(42)
        n = 30
        base = np.random.randn(n, 1)
        correlated_data = np.hstack([
            base + 0.01 * np.random.randn(n, 1),
            base + 0.02 * np.random.randn(n, 1),
            np.random.randn(n, 1)
        ])
        # Add some missing values
        correlated_data[5:10, 1] = np.nan
        
        result1 = mlest(correlated_data, verbose=False)
        assert result1.converged, "Failed to handle near-singular data"
        
        # Test 2: High missingness rate
        high_missing_data = np.random.randn(50, 3)
        missing_mask = np.random.random(high_missing_data.shape) < 0.6  # 60% missing
        high_missing_data[missing_mask] = np.nan
        
        # Only test if enough data remains
        observed_count = np.sum(~np.isnan(high_missing_data))
        if observed_count >= 10:  # Minimum viable data
            result2 = mlest(high_missing_data, verbose=False)
            # Should either converge or fail gracefully
            assert isinstance(result2.converged, bool), "Invalid convergence status"
        
        # Test 3: Single missingness pattern (complete data)
        complete_data = np.random.multivariate_normal([0, 0], [[1, 0.3], [0.3, 1]], 25)
        result3 = mlest(complete_data, verbose=False)
        assert result3.converged, "Failed to handle complete data"
        
        print("‚úÖ Near-singular covariance handled")
        print("‚úÖ High missingness rate handled")
        print("‚úÖ Complete data handled")
        print("‚úÖ REGULATORY VALIDATION: EDGE CASES PASSED")
    
    def test_computational_efficiency(self):
        """
        Test computational efficiency compared to R.
        
        REGULATORY REQUIREMENT: Should not be significantly slower than reference.
        """
        print("\n‚ö° REGULATORY TEST: Computational Efficiency")
        print("=" * 60)
        
        import time
        
        # Test efficiency on Apple dataset
        start_time = time.time()
        result_apple = mlest(datasets.apple, verbose=False)
        apple_time = time.time() - start_time
        
        # Test efficiency on Missvals dataset  
        start_time = time.time()
        result_missvals = mlest(datasets.missvals, max_iter=400, verbose=False)
        missvals_time = time.time() - start_time
        
        # R reference times (from validation output)
        # R: Apple 34 iterations, Missvals 331 iterations
        # Python achieved same results in 14 and ~200 iterations respectively
        
        # Efficiency tests
        assert apple_time < 2.0, f"Apple dataset too slow: {apple_time:.3f}s"
        assert missvals_time < 5.0, f"Missvals dataset too slow: {missvals_time:.3f}s"
        
        # Iteration efficiency (Python should be competitive)
        assert result_apple.n_iter < 50, f"Apple: Too many iterations ({result_apple.n_iter})"
        assert result_missvals.n_iter < 400, f"Missvals: Too many iterations ({result_missvals.n_iter})"
        
        print(f"‚úÖ Apple: {apple_time:.3f}s, {result_apple.n_iter} iterations")
        print(f"‚úÖ Missvals: {missvals_time:.3f}s, {result_missvals.n_iter} iterations")
        print("‚úÖ REGULATORY VALIDATION: EFFICIENCY PASSED")
    
    def test_input_validation_and_error_handling(self):
        """
        Test input validation and error handling.
        
        REGULATORY REQUIREMENT: Must validate inputs and provide clear error messages.
        """
        print("\nüõ°Ô∏è REGULATORY TEST: Input Validation")
        print("=" * 60)
        
        # Test 1: Invalid data dimensions
        with pytest.raises(ValueError, match="2-dimensional"):
            mlest(np.array([1, 2, 3]))  # 1D data
        
        # Test 2: Non-numeric data
        with pytest.raises(ValueError, match="numeric"):
            mlest(np.array([["a", "b"], ["c", "d"]]))
        
        # Test 3: Too few observations
        with pytest.raises(ValueError, match="at least 2 observations"):
            mlest(np.array([[1.0, 2.0]]))  # Only 1 observation
        
        # Test 4: Completely missing variables
        bad_data = np.array([[1.0, np.nan], [2.0, np.nan], [3.0, np.nan]])
        with pytest.raises(ValueError, match="completely missing"):
            mlest(bad_data)
        
        # Test 5: Invalid optimization method
        with pytest.raises(ValueError, match="Newton-CG"):
            mlest(datasets.apple, method='Newton-CG')
        
        print("‚úÖ Dimension validation working")
        print("‚úÖ Data type validation working")  
        print("‚úÖ Sample size validation working")
        print("‚úÖ Missing data validation working")
        print("‚úÖ Method validation working")
        print("‚úÖ REGULATORY VALIDATION: INPUT VALIDATION PASSED")
    
    def test_reproducibility(self):
        """
        Test reproducibility of results.
        
        REGULATORY REQUIREMENT: Results must be reproducible across runs.
        """
        print("\nüîÑ REGULATORY TEST: Reproducibility")
        print("=" * 60)
        
        # Run same analysis multiple times
        results = []
        for i in range(3):
            result = mlest(datasets.apple, verbose=False)
            results.append((result.muhat, result.sigmahat, result.loglik))
        
        # All runs should give identical results (deterministic algorithm)
        for i in range(1, len(results)):
            mu_diff = np.max(np.abs(results[i][0] - results[0][0]))
            sigma_diff = np.max(np.abs(results[i][1] - results[0][1]))
            loglik_diff = abs(results[i][2] - results[0][2])
            
            assert mu_diff < 1e-14, f"Run {i}: Non-reproducible mean estimates"
            assert sigma_diff < 1e-14, f"Run {i}: Non-reproducible covariance estimates"
            assert loglik_diff < 1e-14, f"Run {i}: Non-reproducible log-likelihood"
        
        print("‚úÖ Results identical across multiple runs")
        print("‚úÖ REGULATORY VALIDATION: REPRODUCIBILITY PASSED")


def test_complete_validation_suite():
    """
    Run the complete validation suite using the built-in function.
    
    This test ensures the built-in validation function works correctly.
    """
    print("\nüî¨ COMPLETE VALIDATION SUITE")
    print("=" * 60)
    
    # Run the complete validation
    results = run_validation_suite(verbose=False)
    
    # Both datasets should pass
    assert results['apple'], "Apple dataset validation failed"
    assert results['missvals'], "Missvals dataset validation failed"
    
    print("‚úÖ Built-in validation suite passed")
    print("‚úÖ REGULATORY VALIDATION: COMPLETE SUITE PASSED")


def run_regulatory_tests():
    """
    Main function to run all regulatory tests.
    
    This can be called directly for manual testing.
    """
    print("PyMVNMLE REGULATORY VALIDATION SUITE")
    print("=" * 70)
    print("FDA-Grade Validation Against R mvnmle Reference Implementation")
    print("=" * 70)
    
    # Create test instance
    test_instance = TestRegulatoryValidation()
    test_instance.setup_method()
    
    # Run all tests
    tests = [
        ("Apple Dataset Validation", test_instance.test_apple_dataset_exact_validation),
        ("Missvals Dataset Validation", test_instance.test_missvals_dataset_exact_validation),
        ("Mathematical Properties", test_instance.test_mathematical_properties),
        ("Edge Cases & Robustness", test_instance.test_edge_cases_and_robustness),
        ("Computational Efficiency", test_instance.test_computational_efficiency),
        ("Input Validation", test_instance.test_input_validation_and_error_handling),
        ("Reproducibility", test_instance.test_reproducibility),
        ("Complete Validation Suite", test_complete_validation_suite)
    ]
    
    passed = 0
    failed = 0
    
    for test_name, test_func in tests:
        try:
            print(f"\nRunning: {test_name}")
            test_func()
            passed += 1
            print(f"‚úÖ PASSED: {test_name}")
        except Exception as e:
            failed += 1
            print(f"‚ùå FAILED: {test_name}")
            print(f"Error: {e}")
            import traceback
            traceback.print_exc()
    
    # Final summary
    print("\n" + "=" * 70)
    print("REGULATORY VALIDATION SUMMARY")
    print("=" * 70)
    print(f"Tests Passed: {passed}")
    print(f"Tests Failed: {failed}")
    print(f"Total Tests: {passed + failed}")
    
    if failed == 0:
        print("\nüéâ ALL REGULATORY TESTS PASSED!")
        print("PyMVNMLE is validated for FDA submission and clinical trial use.")
        print("The implementation achieves exact mathematical equivalence with R mvnmle.")
        return True
    else:
        print(f"\n‚ö†Ô∏è {failed} TESTS FAILED!")
        print("PyMVNMLE requires fixes before regulatory approval.")
        return False


if __name__ == "__main__":
    # Run tests when executed directly
    success = run_regulatory_tests()
    sys.exit(0 if success else 1)